{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regression\n",
        "\n",
        "Regression is a logical extension of classification. Rather than just predicting a single value from a set of values, regression is the act of predicting a real number (or continuous variable) from a set of features (represented as numbers).\n",
        "\n",
        "Regression can be harder than classification because, from a mathematical perspective, there are an infinite number of possible output values. Furthermore, we aim to optimize some metric of error between the predicted and true value, as opposed to an accuracy rate. Aside from that, regression and classification are fairly similar. For this reason, we will see a lot of the same underlying concepts applied to regression as we did with classification.\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "The following is a small set of regression use cases that can get you thinking about potential regression problems in your own domain:\n",
        "\n",
        "* Predicting movie viewership: Given information about a movie and the movie-going public, such as how many people have watched the trailer or shared it on social media, you might want to predict how many people are likely to watch the movie when it comes out.\n",
        "\n",
        "* Predicting company revenue: Given a current growth trajectory, the market, and seasonality, you might want to predict how much revenue a company will gain in the future.\n",
        "\n",
        "* Predicting crop yield: Given information about the particular area in which a crop is grown, as well as the current weather throughout the year, you might want to predict the total crop yield for a particular plot of land.\n",
        "\n",
        "## Regression Models in MLlib\n",
        "\n",
        "There are several fundamental regression models in MLlib. This list is current as of Spark 2.4 but will grow:\n",
        "\n",
        "* [Linear regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression)\n",
        "* [Generalized linear regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#generalized-linear-regression)\n",
        "* [Decision tree regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-regression)\n",
        "* [Random forest regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression)\n",
        "* [Gradient-boosted tree regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-regression)\n",
        "* [Survival regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#survival-regression)\n",
        "* [Isotonic regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#isotonic-regression)\n",
        "\n",
        "Here we will cover:\n",
        "* A simple explanation of a few of these models and the intuition behind their algorithms\n",
        "* Model hyperparameters (the different ways that we can initialize the model)\n",
        "* Training parameters (parameters that affect how the model is trained)\n",
        "* Prediction parameters (parameters that affect how predictions are made)\n",
        "\n",
        "You can search over the hyperparameters and training parameters using a `ParamGrid` as we saw before.\n",
        "\n",
        "## Model Scalability\n",
        "\n",
        "The regression models in MLlib all scale to large datasets. Table below is a simple model scalability scorecard that will help you in choosing the best model for your particular task (if scalability is your core consideration). These will depend on your configuration, machine size, and other factors.\n",
        "\n",
        "|Model\t|Number features|\tTraining examples|\n",
        "|--|--|--|\n",
        "|Linear regression|1 to 10 million|No limit|\n",
        "|Generalized linear regression|4,096|No limit|\n",
        "|Decision trees|1,000s|No limit|\n",
        "|Random forest|10,000s|No limit|\n",
        "|Gradient-boosted trees|1,000s|No limit|\n",
        "|Survival regression|1 to 10 million|No limit|\n",
        "|Isotonic regression|N/A|Millions|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import Pretty as disp\n",
        "hint = 'https://raw.githubusercontent.com/soltaniehha/Big-Data-Analytics-for-Business/master/docs/hints/'  # path to hints on GitHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s read in some sample data that we will use throughout the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# the following line gets the bucket name attached to our cluster\n",
        "bucket = spark._jsc.hadoopConfiguration().get(\"fs.gs.system.bucket\")\n",
        "\n",
        "# specifying the path to our bucket where the data is located (no need to edit this path anymore)\n",
        "data = \"gs://\" + bucket + \"/notebooks/jupyter/data/\"\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "small_df = spark.read.load(data + \"regression\")\n",
        "\n",
        "small_df.cache()\n",
        "print(\"sales datasets consists of {} rows.\".format(small_df.count()))\n",
        "small_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression\n",
        "\n",
        "Linear regression assumes that a linear combination of your input features (the sum of each feature multiplied by a weight) results along with an amount of Gaussian error in the output. This linear assumption (along with Gaussian error) does not always hold true, but it does make for a simple, interpretable model that’s hard to overfit. Like logistic regression, Spark implements `ElasticNet` regularization for this, allowing you to mix *L1* and *L2* regularization.\n",
        "\n",
        "### Model Hyperparameters\n",
        "\n",
        "Linear regression has the same model hyperparameters as logistic regression. See below:\n",
        "\n",
        "Model hyperparameters are configurations that determine the basic structure of the model itself. The following hyperparameters are available for linear regression:\n",
        "\n",
        "**`elasticNetParam`** (default: 0.0)\n",
        "\n",
        "The ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. \n",
        "\n",
        "**`epsilon`** (default: 1.35)\n",
        "\n",
        "The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber\n",
        "\n",
        "**`featuresCol`** (default: features)\n",
        "\n",
        "Features column name.\n",
        "\n",
        "**`labelCol`** (default: label)\n",
        "\n",
        "Label column name. \n",
        "\n",
        "**`predictionCol`** (default: prediction)\n",
        "\n",
        "Prediction column name.\n",
        "\n",
        "\n",
        "**`loss`** (default: squaredError)\n",
        "\n",
        "The loss function to be optimized. Supported options: squaredError, huber.\n",
        "\n",
        "**`maxBlockSizeInMB`** (default: 0.0)\n",
        "\n",
        "Maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.\n",
        "\n",
        "\n",
        "**`fitIntercept`** (default: True)\n",
        "\n",
        "Whether to fit an intercept term.\n",
        "\n",
        "**`regParam`** (default: 0.0)\n",
        "\n",
        "A value ≥ 0. that determines how much weight to give to the regularization term in the objective function. Choosing a value here is again going to be a function of noise and dimensionality in our dataset. In a pipeline, try a wide range of values (e.g., 0, 0.01, 0.1, 1).\n",
        "\n",
        "**`solver`** (default: auto)\n",
        "\n",
        "The solver algorithm for optimization. Supported options: auto, normal, l-bfgs.\n",
        "\n",
        "**`standardization`** (default: True)\n",
        "\n",
        "Can be true or false, whether or not to standardize the inputs before passing them into the model.\n",
        "\n",
        "### Training Parameters\n",
        "\n",
        "Linear regression also shares all of the same training parameters from logistic regression. See below:\n",
        "\n",
        "Training parameters are used to specify how we perform our training. Here are the training parameters for logistic regression.\n",
        "\n",
        "**`maxIter`** (default: 100)\n",
        "\n",
        "Max number of iterations (>= 0).\n",
        "\n",
        "\n",
        "**`tol`** (default: 1e-06)\n",
        "\n",
        "This convergence tolerance specifies a threshold by which changes in parameters show that we optimized our weights enough, and can stop iterating. It lets the algorithm stop before `maxIter` iterations. The default value is 1.0E-6. This also shouldn’t be the first parameter you look to tune.\n",
        "\n",
        "**`weightCol`** (undefined)\n",
        "\n",
        "The name of a weight column used to weigh certain rows more than others. This can be a useful tool if you have some other measure of how important a particular training example is and have a weight associated with it. For example, you might have 10,000 examples where you know that some labels are more accurate than others. You can weigh the labels you know are correct more than the ones you don’t. If this is not set or empty, we treat all instance weights as 1.0.\n",
        "\n",
        "### Example\n",
        "\n",
        "Here’s a short example of using linear regression on our sample dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "print(lr.explainParams())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "lrModel = lr.fit(small_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Summary\n",
        "\n",
        "Just as in logistic regression, we get detailed training information back from our model. The summary method returns a summary object with several fields. Let’s go through these in turn. \n",
        "\n",
        "* The residuals are simply the weights for each of the features that we input into the model. \n",
        "* The objective history shows how our training is going at every iteration. \n",
        "* The root mean squared error is a measure of how well our line is fitting the data, determined by looking at the distance between each predicted value and the actual value in the data. \n",
        "* The R-squared variable is a measure of the proportion of the variance of the predicted variable that is captured by the model.\n",
        "\n",
        "There are a number of metrics and summary information that may be relevant to your use case. This section demonstrates the API, but does not comprehensively cover every metric (consult the API documentation for more information).\n",
        "\n",
        "Print the coefficients and intercept for linear regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
        "print(\"Intercept: %s\" % str(lrModel.intercept))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summarize the model over the training set and print out some metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "trainingSummary = lrModel.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
        "print(\"r2: %f\" % trainingSummary.r2)\n",
        "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
        "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Residuals:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "trainingSummary.residuals.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Your turn\n",
        "\n",
        "Using a new dataset find a linear regression model that fits the data best.\n",
        "\n",
        "Dataset: [Online News Popularity Data Set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) from UC Irvine datasets\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field) \n",
        "\n",
        "Attribute Information: \n",
        "\n",
        "0. url: URL of the article (non-predictive) \n",
        "1. timedelta: Days between the article publication and the dataset acquisition (non-predictive) \n",
        "2. n_tokens_title: Number of words in the title \n",
        "3. n_tokens_content: Number of words in the content \n",
        "4. n_unique_tokens: Rate of unique words in the content \n",
        "5. n_non_stop_words: Rate of non-stop words in the content \n",
        "6. n_non_stop_unique_tokens: Rate of unique non-stop words in the content \n",
        "7. num_hrefs: Number of links \n",
        "8. num_self_hrefs: Number of links to other articles published by Mashable \n",
        "9. num_imgs: Number of images \n",
        "10. num_videos: Number of videos \n",
        "11. average_token_length: Average length of the words in the content \n",
        "12. num_keywords: Number of keywords in the metadata \n",
        "13. data_channel_is_lifestyle: Is data channel 'Lifestyle'? \n",
        "14. data_channel_is_entertainment: Is data channel 'Entertainment'? \n",
        "15. data_channel_is_bus: Is data channel 'Business'? \n",
        "16. data_channel_is_socmed: Is data channel 'Social Media'? \n",
        "17. data_channel_is_tech: Is data channel 'Tech'? \n",
        "18. data_channel_is_world: Is data channel 'World'? \n",
        "19. kw_min_min: Worst keyword (min. shares) \n",
        "20. kw_max_min: Worst keyword (max. shares) \n",
        "21. kw_avg_min: Worst keyword (avg. shares) \n",
        "22. kw_min_max: Best keyword (min. shares) \n",
        "23. kw_max_max: Best keyword (max. shares) \n",
        "24. kw_avg_max: Best keyword (avg. shares) \n",
        "25. kw_min_avg: Avg. keyword (min. shares) \n",
        "26. kw_max_avg: Avg. keyword (max. shares) \n",
        "27. kw_avg_avg: Avg. keyword (avg. shares) \n",
        "28. self_reference_min_shares: Min. shares of referenced articles in Mashable \n",
        "29. self_reference_max_shares: Max. shares of referenced articles in Mashable \n",
        "30. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable \n",
        "31. weekday_is_monday: Was the article published on a Monday? \n",
        "32. weekday_is_tuesday: Was the article published on a Tuesday? \n",
        "33. weekday_is_wednesday: Was the article published on a Wednesday? \n",
        "34. weekday_is_thursday: Was the article published on a Thursday? \n",
        "35. weekday_is_friday: Was the article published on a Friday? \n",
        "36. weekday_is_saturday: Was the article published on a Saturday? \n",
        "37. weekday_is_sunday: Was the article published on a Sunday? \n",
        "38. is_weekend: Was the article published on the weekend? \n",
        "39. LDA_00: Closeness to LDA topic 0 \n",
        "40. LDA_01: Closeness to LDA topic 1 \n",
        "41. LDA_02: Closeness to LDA topic 2 \n",
        "42. LDA_03: Closeness to LDA topic 3 \n",
        "43. LDA_04: Closeness to LDA topic 4 \n",
        "44. global_subjectivity: Text subjectivity \n",
        "45. global_sentiment_polarity: Text sentiment polarity \n",
        "46. global_rate_positive_words: Rate of positive words in the content \n",
        "47. global_rate_negative_words: Rate of negative words in the content \n",
        "48. rate_positive_words: Rate of positive words among non-neutral tokens \n",
        "49. rate_negative_words: Rate of negative words among non-neutral tokens \n",
        "50. avg_positive_polarity: Avg. polarity of positive words \n",
        "51. min_positive_polarity: Min. polarity of positive words \n",
        "52. max_positive_polarity: Max. polarity of positive words \n",
        "53. avg_negative_polarity: Avg. polarity of negative words \n",
        "54. min_negative_polarity: Min. polarity of negative words \n",
        "55. max_negative_polarity: Max. polarity of negative words \n",
        "56. title_subjectivity: Title subjectivity \n",
        "57. title_sentiment_polarity: Title polarity \n",
        "58. abs_title_subjectivity: Absolute subjectivity level \n",
        "59. abs_title_sentiment_polarity: Absolute polarity level \n",
        "60. shares: Number of shares (target)\n",
        "\n",
        "The data is in a file named, **OnlineNewsPopularity.csv**\n",
        "\n",
        "First upload the data to your Google Cloud Storage and then load it to a PySpark DataFrame. Then show the first couple of rows and its schema. You can also cache it for a better performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Uncomment and execute the cell below to get help\n",
        "#disp(hint + '12-01-load')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define an RFormula that uses all of the columns as features except the one(s) that are not numerical and call it `supervised`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Uncomment and execute the cell below to get help\n",
        "#disp(hint + '12-01-RFormula')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the RFormula transformer and call it `fittedRF`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Uncomment and execute the cell below to get help\n",
        "#disp(hint + '12-01-fittedRF')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using `fittedRF` transform our `df` DataFrame. Call this `preparedDF`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Uncomment and execute the cell below to get help\n",
        "#disp(hint + '12-01-preparedDF')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the first couple of rows of `preparedDF`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "preparedDF.select('features', 'label').show(2, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we will retrieve the name of the columns used to make our feature vector and store them in a pandas DataFrame. Notice that we don't have any binary terms, so we have dropped that from our metadata extraction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "featureCols = pd.DataFrame(preparedDF.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"numeric\"]).sort_values(\"idx\")\n",
        "\n",
        "featureCols = featureCols.set_index('idx')\n",
        "featureCols.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instantiate a linear regression, call it `lr`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Uncomment and execute the cell below to get help\n",
        "#disp(hint + '12-01-lr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the model using `preparedDF`. Call this model `lrModel`: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Uncomment and execute the cell below to get help\n",
        "#disp(hint + '12-01-lrModel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Print coefficients\n",
        "* Using the model summary output some of its components and assess the goodness of fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# SOLUTION: Uncomment and execute the cell below to get help\n",
        "#disp(hint + '12-01-summ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Try again but this time divid the data into train and test and assess the model on the unseen data\n",
        "* Design a pipeline and perform hyper-parameter tunning\n",
        "\n",
        "## Decision Trees\n",
        "\n",
        "Decision trees as applied to regression work fairly similarly to decision trees applied to classification. The main difference is that decision trees for regression output a single number per leaf node instead of a label (as we saw with classification). The same interpretability properties and model structure still apply. In short, rather than trying to train coeffiecients to model a function, decision tree regression simply creates a tree to predict the numerical outputs. This is of significant consequence because unlike generalized linear regression, we can predict nonlinear functions in the input data. This also creates a significant risk of overfitting the data, so we need to be careful when tuning and evaluating these models.\n",
        "\n",
        "We also covered decision trees in the previous class. For more information on this topic, consult [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/).\n",
        "\n",
        "### Model Hyperparameters\n",
        "\n",
        "The model hyperparameters that apply decision trees for regression are the same as those for classification except for a slight change to the impurity parameter. See notebook from previous class for more information on the other hyperparameters:\n",
        "\n",
        "**impurity**\n",
        "\n",
        "The impurity parameter represents the metric (information gain) for whether or not the model should split at a particular leaf node with a particular value or keep it as is. The only metric currently supported for regression trees is “variance.”\n",
        "\n",
        "### Training Parameters\n",
        "\n",
        "In addition to hyperparameters, classification and regression trees also share the same training parameters. \n",
        "\n",
        "**Example**\n",
        "\n",
        "Here’s a short example of using a decision tree regressor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "dtr = DecisionTreeRegressor()\n",
        "print(dtr.explainParams())\n",
        "dtrModel = dtr.fit(small_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = small_df.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Train a DecisionTree model.\n",
        "dt = DecisionTreeRegressor(featuresCol=\"features\")\n",
        "\n",
        "# Train model.  This also runs the indexer.\n",
        "model = dt.fit(trainingData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predicting and evaluating on test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\")\n",
        "\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
        "\n",
        "# Summary\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Your turn\n",
        "\n",
        "Repeat this with the Online News Popularity Data Set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make predictions on test set and check the model performance against it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* What kind of improvements can you make to better this model?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
